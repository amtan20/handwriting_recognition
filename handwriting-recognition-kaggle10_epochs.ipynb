{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T00:46:13.943368Z",
     "iopub.status.busy": "2021-08-09T00:46:13.942922Z",
     "iopub.status.idle": "2021-08-09T00:46:22.003698Z",
     "shell.execute_reply": "2021-08-09T00:46:22.002734Z",
     "shell.execute_reply.started": "2021-08-09T00:46:13.943277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.5.3-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.5.3\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T00:46:27.085132Z",
     "iopub.status.busy": "2021-08-09T00:46:27.084803Z",
     "iopub.status.idle": "2021-08-09T00:46:28.597460Z",
     "shell.execute_reply": "2021-08-09T00:46:28.595413Z",
     "shell.execute_reply.started": "2021-08-09T00:46:27.085099Z"
    },
    "id": "hbeM9aEXGgh1"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "# Mixed Precision Training\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09hv06ZVGGzy"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:26.731156Z",
     "iopub.status.busy": "2021-08-09T02:21:26.730785Z",
     "iopub.status.idle": "2021-08-09T02:21:26.793730Z",
     "shell.execute_reply": "2021-08-09T02:21:26.792760Z",
     "shell.execute_reply.started": "2021-08-09T02:21:26.731122Z"
    },
    "id": "y6xlYTIjBQFe",
    "outputId": "a1c7a3bf-ad91-4722-e580-024208f9cef1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>IDENTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VALIDATION_0001.jpg</td>\n",
       "      <td>BILEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VALIDATION_0002.jpg</td>\n",
       "      <td>LAUMIONIER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VALIDATION_0003.jpg</td>\n",
       "      <td>LEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VALIDATION_0004.jpg</td>\n",
       "      <td>JEAN-ROCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VALIDATION_0005.jpg</td>\n",
       "      <td>RUPP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FILENAME    IDENTITY\n",
       "0  VALIDATION_0001.jpg       BILEL\n",
       "1  VALIDATION_0002.jpg  LAUMIONIER\n",
       "2  VALIDATION_0003.jpg         LEA\n",
       "3  VALIDATION_0004.jpg   JEAN-ROCH\n",
       "4  VALIDATION_0005.jpg        RUPP"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_validation_v2.csv') # Locally\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:26.800171Z",
     "iopub.status.busy": "2021-08-09T02:21:26.798128Z",
     "iopub.status.idle": "2021-08-09T02:21:27.200044Z",
     "shell.execute_reply": "2021-08-09T02:21:27.199198Z",
     "shell.execute_reply.started": "2021-08-09T02:21:26.800129Z"
    },
    "id": "3W03dwXmEZVo"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_train_v2.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_test_v2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:27.202209Z",
     "iopub.status.busy": "2021-08-09T02:21:27.201864Z",
     "iopub.status.idle": "2021-08-09T02:21:27.243991Z",
     "shell.execute_reply": "2021-08-09T02:21:27.243116Z",
     "shell.execute_reply.started": "2021-08-09T02:21:27.202180Z"
    },
    "id": "BS9uEjhhJZRV",
    "outputId": "0472dff6-650b-405e-9873-8deea2e3f17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls in train: 565\n",
      "Number of nulls in valid: 78\n"
     ]
    }
   ],
   "source": [
    "# Are there any null values? \n",
    "\n",
    "print(\"Number of nulls in train:\", df_train['IDENTITY'].isnull().sum())\n",
    "print(\"Number of nulls in valid:\",df_valid['IDENTITY'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:27.246343Z",
     "iopub.status.busy": "2021-08-09T02:21:27.245971Z",
     "iopub.status.idle": "2021-08-09T02:21:27.290225Z",
     "shell.execute_reply": "2021-08-09T02:21:27.289244Z",
     "shell.execute_reply.started": "2021-08-09T02:21:27.246303Z"
    },
    "id": "TXeVb9ICJqeQ",
    "outputId": "abc016dc-d18e-4599-e98d-f3b6337c8a3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>IDENTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>TRAIN_01914.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>TRAIN_02130.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>TRAIN_02625.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>TRAIN_04629.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>TRAIN_04873.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328491</th>\n",
       "      <td>TRAIN_328492.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328653</th>\n",
       "      <td>TRAIN_328654.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329959</th>\n",
       "      <td>TRAIN_329960.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330160</th>\n",
       "      <td>TRAIN_330161.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330164</th>\n",
       "      <td>TRAIN_330165.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                FILENAME IDENTITY\n",
       "1913     TRAIN_01914.jpg      NaN\n",
       "2129     TRAIN_02130.jpg      NaN\n",
       "2624     TRAIN_02625.jpg      NaN\n",
       "4628     TRAIN_04629.jpg      NaN\n",
       "4872     TRAIN_04873.jpg      NaN\n",
       "...                  ...      ...\n",
       "328491  TRAIN_328492.jpg      NaN\n",
       "328653  TRAIN_328654.jpg      NaN\n",
       "329959  TRAIN_329960.jpg      NaN\n",
       "330160  TRAIN_330161.jpg      NaN\n",
       "330164  TRAIN_330165.jpg      NaN\n",
       "\n",
       "[565 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at some of them \n",
    "df_train.loc[df_train['IDENTITY'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:27.292002Z",
     "iopub.status.busy": "2021-08-09T02:21:27.291635Z",
     "iopub.status.idle": "2021-08-09T02:21:27.389934Z",
     "shell.execute_reply": "2021-08-09T02:21:27.389002Z",
     "shell.execute_reply.started": "2021-08-09T02:21:27.291965Z"
    },
    "id": "9MWDoHyeKRJe"
   },
   "outputs": [],
   "source": [
    "# Drop the rows with null values for the label (IDENTITY column)\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_valid.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:27.391616Z",
     "iopub.status.busy": "2021-08-09T02:21:27.391218Z",
     "iopub.status.idle": "2021-08-09T02:21:27.455131Z",
     "shell.execute_reply": "2021-08-09T02:21:27.454346Z",
     "shell.execute_reply.started": "2021-08-09T02:21:27.391578Z"
    },
    "id": "XPeLYqcZCo6v",
    "outputId": "765bd88e-b850-4e8b-e734-d79ac6e31a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "12\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# How many unreadable images are there in each set? \n",
    "print(len(df_train.loc[df_train['IDENTITY']=='UNREADABLE']))\n",
    "print(len(df_valid.loc[df_valid['IDENTITY']=='UNREADABLE']))\n",
    "print(len(df_test.loc[df_test['IDENTITY']=='UNREADABLE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:27.456801Z",
     "iopub.status.busy": "2021-08-09T02:21:27.456434Z",
     "iopub.status.idle": "2021-08-09T02:21:27.532492Z",
     "shell.execute_reply": "2021-08-09T02:21:27.531591Z",
     "shell.execute_reply.started": "2021-08-09T02:21:27.456763Z"
    },
    "id": "v4VEmmGqDv0l"
   },
   "outputs": [],
   "source": [
    "# Remove the unreadable images from the train and valid sets\n",
    "# Q: In the Kaggle notebook, they don't remove these from the test. Why? \n",
    "\n",
    "df_train = df_train[df_train['IDENTITY'] != 'UNREADABLE']\n",
    "df_valid = df_valid[df_valid['IDENTITY'] != 'UNREADABLE']\n",
    "df_test = df_test[df_test['IDENTITY'] != 'UNREADABLE']\n",
    "\n",
    "df_train.reset_index(inplace = True, drop=True) \n",
    "df_valid.reset_index(inplace = True, drop=True)\n",
    "df_test.reset_index(inplace = True, drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:27.536660Z",
     "iopub.status.busy": "2021-08-09T02:21:27.536223Z",
     "iopub.status.idle": "2021-08-09T02:21:27.736141Z",
     "shell.execute_reply": "2021-08-09T02:21:27.735248Z",
     "shell.execute_reply.started": "2021-08-09T02:21:27.536621Z"
    },
    "id": "oY96cw9hFxjb"
   },
   "outputs": [],
   "source": [
    "# There are some labels that are lowercase. Convert all labels to uppercase\n",
    "\n",
    "df_train['IDENTITY'] = df_train['IDENTITY'].str.upper()\n",
    "df_valid['IDENTITY'] = df_valid['IDENTITY'].str.upper()\n",
    "df_test['IDENTITY'] = df_test['IDENTITY'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:27.738741Z",
     "iopub.status.busy": "2021-08-09T02:21:27.738206Z",
     "iopub.status.idle": "2021-08-09T02:21:27.990654Z",
     "shell.execute_reply": "2021-08-09T02:21:27.989516Z",
     "shell.execute_reply.started": "2021-08-09T02:21:27.738701Z"
    },
    "id": "yztN_FayJEyr",
    "outputId": "95ecf2ad-d35d-4153-cbd1-9d396797af67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        LABEL LENGTH\n",
      "count  330294.000000\n",
      "mean        6.546531\n",
      "std         2.123296\n",
      "min         1.000000\n",
      "25%         5.000000\n",
      "50%         6.000000\n",
      "75%         7.000000\n",
      "max        34.000000\n",
      "       LABEL LENGTH\n",
      "count  41280.000000\n",
      "mean       6.556613\n",
      "std        2.127069\n",
      "min        1.000000\n",
      "25%        5.000000\n",
      "50%        6.000000\n",
      "75%        7.000000\n",
      "max       21.000000\n",
      "       LABEL LENGTH\n",
      "count  41289.000000\n",
      "mean       6.545860\n",
      "std        2.137525\n",
      "min        1.000000\n",
      "25%        5.000000\n",
      "50%        6.000000\n",
      "75%        7.000000\n",
      "max       24.000000\n"
     ]
    }
   ],
   "source": [
    "# How long is the longest name that we'll encounter? \n",
    "\n",
    "df_train['LABEL LENGTH'] = df_train['IDENTITY'].apply(lambda x: len(x))\n",
    "df_valid['LABEL LENGTH'] = df_valid['IDENTITY'].apply(lambda x: len(x))\n",
    "df_test['LABEL LENGTH'] = df_test['IDENTITY'].apply(lambda x: len(x))\n",
    "\n",
    "print(df_train.describe()) # 34 for the training set \n",
    "print(df_valid.describe()) # 21 for the valid set\n",
    "print(df_test.describe()) # 24 for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VY8MexFGVl5"
   },
   "source": [
    "# Prepare Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:27.992724Z",
     "iopub.status.busy": "2021-08-09T02:21:27.992323Z",
     "iopub.status.idle": "2021-08-09T02:21:28.000069Z",
     "shell.execute_reply": "2021-08-09T02:21:27.999122Z",
     "shell.execute_reply.started": "2021-08-09T02:21:27.992684Z"
    },
    "id": "wmOClSZDF-Ca"
   },
   "outputs": [],
   "source": [
    "# Code borrowed from https://www.kaggle.com/samfc10/handwriting-recognition-using-crnn-in-keras\n",
    "\n",
    "def preprocess(img):\n",
    "    (h, w) = img.shape\n",
    "    \n",
    "    final_img = np.ones([64, 256])*255 # blank white image\n",
    "    \n",
    "    # Width and height are cropped if greater than 256x64; If smaler, image is padded with white pixesls\n",
    "    if w > 256:\n",
    "        img = img[:, :256]\n",
    "        \n",
    "    if h > 64:\n",
    "        img = img[:64, :]\n",
    "    \n",
    "    \n",
    "    final_img[:h, :w] = img\n",
    "    # Rotate clockwise\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUws6oFtPWBK"
   },
   "source": [
    "# Prepare Labels: Convert names into a sequence of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:28.002079Z",
     "iopub.status.busy": "2021-08-09T02:21:28.001477Z",
     "iopub.status.idle": "2021-08-09T02:21:28.012716Z",
     "shell.execute_reply": "2021-08-09T02:21:28.011945Z",
     "shell.execute_reply.started": "2021-08-09T02:21:28.002038Z"
    },
    "id": "zgK3fYYFOZQ7"
   },
   "outputs": [],
   "source": [
    "# Code adapted from same notebook as above \n",
    "\n",
    "alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\n",
    "max_str_len = 64 # max length of input labels\n",
    "num_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\n",
    "num_of_timestamps = 64 # max length of predicted labels \n",
    "\n",
    "def label_to_num(label):\n",
    "    label_num = []\n",
    "    for ch in label:\n",
    "        label_num.append(alphabets.find(ch))\n",
    "        \n",
    "    return np.array(label_num)\n",
    "\n",
    "def num_to_label(num):\n",
    "    ret = \"\"\n",
    "    for ch in num:\n",
    "        if ch == -1:  # CTC Blank\n",
    "            break\n",
    "        else:\n",
    "            ret+=alphabets[ch]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:28.014388Z",
     "iopub.status.busy": "2021-08-09T02:21:28.014025Z",
     "iopub.status.idle": "2021-08-09T02:21:28.021772Z",
     "shell.execute_reply": "2021-08-09T02:21:28.020911Z",
     "shell.execute_reply.started": "2021-08-09T02:21:28.014335Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_label(row):\n",
    "    label = np.zeros(max_str_len)\n",
    "    for i in range(max_str_len):\n",
    "        label[0:len(row)] = label_to_num(row)\n",
    "\n",
    "    return label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:21:28.023081Z",
     "iopub.status.busy": "2021-08-09T02:21:28.022816Z",
     "iopub.status.idle": "2021-08-09T02:23:55.228057Z",
     "shell.execute_reply": "2021-08-09T02:23:55.227214Z",
     "shell.execute_reply.started": "2021-08-09T02:21:28.023047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>IDENTITY</th>\n",
       "      <th>LABEL LENGTH</th>\n",
       "      <th>ENCODED LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00001.jpg</td>\n",
       "      <td>BALTHAZAR</td>\n",
       "      <td>9</td>\n",
       "      <td>[1.0, 0.0, 11.0, 19.0, 7.0, 0.0, 25.0, 0.0, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00002.jpg</td>\n",
       "      <td>SIMON</td>\n",
       "      <td>5</td>\n",
       "      <td>[18.0, 8.0, 12.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00003.jpg</td>\n",
       "      <td>BENES</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.0, 4.0, 13.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00004.jpg</td>\n",
       "      <td>LA LOVE</td>\n",
       "      <td>7</td>\n",
       "      <td>[11.0, 0.0, 28.0, 11.0, 14.0, 21.0, 4.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00005.jpg</td>\n",
       "      <td>DAPHNE</td>\n",
       "      <td>6</td>\n",
       "      <td>[3.0, 0.0, 15.0, 7.0, 13.0, 4.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330289</th>\n",
       "      <td>TRAIN_330957.jpg</td>\n",
       "      <td>LENNY</td>\n",
       "      <td>5</td>\n",
       "      <td>[11.0, 4.0, 13.0, 13.0, 24.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330290</th>\n",
       "      <td>TRAIN_330958.jpg</td>\n",
       "      <td>TIFFANY</td>\n",
       "      <td>7</td>\n",
       "      <td>[19.0, 8.0, 5.0, 5.0, 0.0, 13.0, 24.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330291</th>\n",
       "      <td>TRAIN_330959.jpg</td>\n",
       "      <td>COUTINHO DESA</td>\n",
       "      <td>13</td>\n",
       "      <td>[2.0, 14.0, 20.0, 19.0, 8.0, 13.0, 7.0, 14.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330292</th>\n",
       "      <td>TRAIN_330960.jpg</td>\n",
       "      <td>MOURAD</td>\n",
       "      <td>6</td>\n",
       "      <td>[12.0, 14.0, 20.0, 17.0, 0.0, 3.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330293</th>\n",
       "      <td>TRAIN_330961.jpg</td>\n",
       "      <td>HELOISE</td>\n",
       "      <td>7</td>\n",
       "      <td>[7.0, 4.0, 11.0, 14.0, 8.0, 18.0, 4.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330294 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                FILENAME       IDENTITY  LABEL LENGTH  \\\n",
       "0        TRAIN_00001.jpg      BALTHAZAR             9   \n",
       "1        TRAIN_00002.jpg          SIMON             5   \n",
       "2        TRAIN_00003.jpg          BENES             5   \n",
       "3        TRAIN_00004.jpg        LA LOVE             7   \n",
       "4        TRAIN_00005.jpg         DAPHNE             6   \n",
       "...                  ...            ...           ...   \n",
       "330289  TRAIN_330957.jpg          LENNY             5   \n",
       "330290  TRAIN_330958.jpg        TIFFANY             7   \n",
       "330291  TRAIN_330959.jpg  COUTINHO DESA            13   \n",
       "330292  TRAIN_330960.jpg         MOURAD             6   \n",
       "330293  TRAIN_330961.jpg        HELOISE             7   \n",
       "\n",
       "                                            ENCODED LABEL  \n",
       "0       [1.0, 0.0, 11.0, 19.0, 7.0, 0.0, 25.0, 0.0, 17...  \n",
       "1       [18.0, 8.0, 12.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0...  \n",
       "2       [1.0, 4.0, 13.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "3       [11.0, 0.0, 28.0, 11.0, 14.0, 21.0, 4.0, 0.0, ...  \n",
       "4       [3.0, 0.0, 15.0, 7.0, 13.0, 4.0, 0.0, 0.0, 0.0...  \n",
       "...                                                   ...  \n",
       "330289  [11.0, 4.0, 13.0, 13.0, 24.0, 0.0, 0.0, 0.0, 0...  \n",
       "330290  [19.0, 8.0, 5.0, 5.0, 0.0, 13.0, 24.0, 0.0, 0....  \n",
       "330291  [2.0, 14.0, 20.0, 19.0, 8.0, 13.0, 7.0, 14.0, ...  \n",
       "330292  [12.0, 14.0, 20.0, 17.0, 0.0, 3.0, 0.0, 0.0, 0...  \n",
       "330293  [7.0, 4.0, 11.0, 14.0, 8.0, 18.0, 4.0, 0.0, 0....  \n",
       "\n",
       "[330294 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ENCODED LABEL'] = df_train['IDENTITY'].apply(lambda x: encode_label(x))\n",
    "df_valid['ENCODED LABEL'] = df_valid['IDENTITY'].apply(lambda x: encode_label(x))\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:23:55.229790Z",
     "iopub.status.busy": "2021-08-09T02:23:55.229441Z",
     "iopub.status.idle": "2021-08-09T02:23:55.234433Z",
     "shell.execute_reply": "2021-08-09T02:23:55.233352Z",
     "shell.execute_reply.started": "2021-08-09T02:23:55.229754Z"
    },
    "id": "_S2JurhXNnD4",
    "outputId": "3ec9a2c6-aa8f-41fe-b95c-04b922a65e2f"
   },
   "outputs": [],
   "source": [
    "# Code adapted from notebook -- WHERE DO WE USE THIS????\n",
    "\n",
    "# TRAIN\n",
    "# train_y = np.ones([train_size, max_str_len]) * 0\n",
    "# train_label_len = np.zeros([train_size, 1])\n",
    "# train_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\n",
    "# train_output = np.zeros([train_size])\n",
    "\n",
    "# for i in range(train_size):\n",
    "#     train_label_len[i] = len(df_train.loc[i, 'IDENTITY'])\n",
    "#     train_y[i, 0:len(df_train.loc[i, 'IDENTITY'])]= label_to_num(df_train.loc[i, 'IDENTITY'])\n",
    "\n",
    "# # VALID \n",
    "# valid_y = np.ones([valid_size, max_str_len]) * -1\n",
    "# valid_label_len = np.zeros([valid_size, 1])\n",
    "# valid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\n",
    "# valid_output = np.zeros([valid_size])\n",
    "\n",
    "# for i in range(valid_size):\n",
    "#     valid_label_len[i] = len(df_valid.loc[i, 'IDENTITY'])\n",
    "#     valid_y[i, 0:len(df_valid.loc[i, 'IDENTITY'])]= label_to_num(df_valid.loc[i, 'IDENTITY'])\n",
    "\n",
    "# # VERIFY        \n",
    "# print('True label : ',df_train.loc[49, 'IDENTITY'] , '\\ntrain_y : ',train_y[49],'\\ntrain_label_len : ',train_label_len[49], \n",
    "#       '\\ntrain_input_len : ', train_input_len[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:23:55.236453Z",
     "iopub.status.busy": "2021-08-09T02:23:55.236032Z",
     "iopub.status.idle": "2021-08-09T02:23:55.248168Z",
     "shell.execute_reply": "2021-08-09T02:23:55.247390Z",
     "shell.execute_reply.started": "2021-08-09T02:23:55.236369Z"
    },
    "id": "NVZ180TbIp3V"
   },
   "outputs": [],
   "source": [
    "# Create a dataset \n",
    "\n",
    "class HandwritingDataset(Dataset):\n",
    "    def __init__(self, df, folder_path):\n",
    "        self.df = df\n",
    "        self.folder_path = folder_path  # ex. '/content/train_v2/train/'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # retrieve image\n",
    "        path = self.folder_path+self.df.loc[idx,'FILENAME']\n",
    "        \n",
    "        # read the img\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img = preprocess(img)\n",
    "        \n",
    "        # convert to [0,1] scale -> normalize\n",
    "        img = torch.tensor(img / 255.).float()\n",
    "        \n",
    "        # Encode the label \n",
    "        label = torch.tensor(self.df.loc[idx,'ENCODED LABEL'])\n",
    "        #label = torch.tensor(label_to_num(self.df.loc[idx,'IDENTITY'])) # Returns label as a sequence of numbers \n",
    "        label_length = self.df.loc[idx,'LABEL LENGTH']\n",
    "        \n",
    "        return img, label, label_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:23:55.250008Z",
     "iopub.status.busy": "2021-08-09T02:23:55.249644Z",
     "iopub.status.idle": "2021-08-09T02:23:55.280643Z",
     "shell.execute_reply": "2021-08-09T02:23:55.279873Z",
     "shell.execute_reply.started": "2021-08-09T02:23:55.249965Z"
    },
    "id": "wjI7EL_NNXde",
    "outputId": "af2f0a51-7387-45af-a1cb-e80163614943"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 0.9686, 0.9961, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.9961, 0.9961]]),\n",
       " tensor([ 1.,  0., 11., 19.,  7.,  0., 25.,  0., 17.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=torch.float64),\n",
       " 9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = df_train.iloc[:500]\n",
    "ds_train = HandwritingDataset(df_train, '/kaggle/input/handwriting-recognition/train_v2/train/')\n",
    "next(iter(ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:23:55.282098Z",
     "iopub.status.busy": "2021-08-09T02:23:55.281750Z",
     "iopub.status.idle": "2021-08-09T02:23:55.294923Z",
     "shell.execute_reply": "2021-08-09T02:23:55.294165Z",
     "shell.execute_reply.started": "2021-08-09T02:23:55.282063Z"
    },
    "id": "uEiwKSHVJrM9",
    "outputId": "d93b3b3b-1d6f-4c90-8ed8-2fb47cace54b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
       " tensor([ 1.,  8., 11.,  4., 11.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=torch.float64),\n",
       " 5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_valid = df_valid.iloc[:500]\n",
    "ds_valid = HandwritingDataset(df_valid, '/kaggle/input/handwriting-recognition/validation_v2/validation/')\n",
    "\n",
    "next(iter(ds_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:23:55.296628Z",
     "iopub.status.busy": "2021-08-09T02:23:55.296119Z",
     "iopub.status.idle": "2021-08-09T02:23:55.315697Z",
     "shell.execute_reply": "2021-08-09T02:23:55.314656Z",
     "shell.execute_reply.started": "2021-08-09T02:23:55.296591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataloaders \n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size = 32, shuffle=True)\n",
    "dl_valid = DataLoader(ds_valid, batch_size = 32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:23:55.317557Z",
     "iopub.status.busy": "2021-08-09T02:23:55.317183Z",
     "iopub.status.idle": "2021-08-09T02:23:55.377154Z",
     "shell.execute_reply": "2021-08-09T02:23:55.376186Z",
     "shell.execute_reply.started": "2021-08-09T02:23:55.317521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9882, 0.9961],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9843, 0.9961, 0.9922],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.7333, 0.9882, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.0471, 0.2353, 0.3725],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.8471, 0.5020, 0.1216]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 1.0000, 0.9882],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.3843, 0.3608, 0.3961],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]),\n",
       " tensor([[ 1.,  8., 11.,  ...,  0.,  0.,  0.],\n",
       "         [11.,  0., 20.,  ...,  0.,  0.,  0.],\n",
       "         [11.,  4.,  0.,  ...,  0.,  0.,  0.],\n",
       "         ...,\n",
       "         [15., 17.,  8.,  ...,  0.,  0.,  0.],\n",
       "         [ 7., 20.,  6.,  ...,  0.,  0.,  0.],\n",
       "         [12.,  0., 14.,  ...,  0.,  0.,  0.]], dtype=torch.float64),\n",
       " tensor([ 5, 10,  3,  9,  4,  6,  6,  6, 11,  6,  4,  6,  7,  5,  7,  5,  7,  9,\n",
       "          8, 11,  6,  5,  8,  8,  8,  6,  5,  8, 11,  6,  4,  5])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pS7tEE3XK8r"
   },
   "source": [
    "## CNN Architecture --> RNN Arhitecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:23:55.378858Z",
     "iopub.status.busy": "2021-08-09T02:23:55.378479Z",
     "iopub.status.idle": "2021-08-09T02:23:55.392791Z",
     "shell.execute_reply": "2021-08-09T02:23:55.391597Z",
     "shell.execute_reply.started": "2021-08-09T02:23:55.378822Z"
    },
    "id": "rH4LIYXxD8Kn"
   },
   "outputs": [],
   "source": [
    "class CNN_RNN(nn.Module):\n",
    "    \"\"\"CNN and RNN model from class\"\"\"\n",
    "    def __init__(self, p=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # same padding!\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # # doing this to shrink size enough!\n",
    "        # self.conv4 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=3, padding=1)\n",
    "        \n",
    "        # pooling\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=(1,2))\n",
    "        \n",
    "        # activation\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "        # batchnorm\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Linear Layer (Dense Layer)\n",
    "        self.linear1 = nn.Linear(in_features=1024, out_features=64)\n",
    "        self.linear2 = nn.Linear(in_features=1024, out_features=30)\n",
    "\n",
    "        # RNN Layer --> Single LSTM with num_layers=2\n",
    "        #self.lstm1 = nn.LSTM(input_size=64, hidden_size=600, batch_first=True, bidirectional=True, num_layers=2, proj_size=512)\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=512, batch_first=True, bidirectional=True, num_layers=2)\n",
    "\n",
    "        self.unroll = nn.Flatten()\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # CNN\n",
    "        # Start with image that is 256 wide x 64 tall and 1 channel\n",
    "        # End with 64 wide x 8 tall and 128 channels\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool_1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool_1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool_2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "\n",
    "        # CNN to RNN\n",
    "        # Reshape to a sequence vector that is 64 wide and 1024 deep \n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "\n",
    "        x = torch.reshape(x,(batch_size,64,-1)) # or 1024 instead of -1?? \n",
    "\n",
    "        x = self.linear1(x) \n",
    "        # Now we shrink the sequence vector to be 512 deep \n",
    "\n",
    "        # RNN\n",
    "        # RNN layer outputs a tuple, the output and the final hidden state\n",
    "        # taking the final hidden state as output\n",
    "\n",
    "        \n",
    "        x = self.lstm1(x)[0] #[0] to get outputs, not hidden\n",
    "\n",
    "        # OUTPUT\n",
    "        x = self.linear2(x) # torch.Size([2, 2, 30])\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:23:55.394703Z",
     "iopub.status.busy": "2021-08-09T02:23:55.394283Z",
     "iopub.status.idle": "2021-08-09T02:23:55.590369Z",
     "shell.execute_reply": "2021-08-09T02:23:55.589490Z",
     "shell.execute_reply.started": "2021-08-09T02:23:55.394668Z"
    },
    "id": "elpMbwanO5TY",
    "outputId": "7b19b1ba-7b37-4beb-a171-90c76cbe3f13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_RNN                                  --                        --\n",
       "├─Conv2d: 1-1                            [2, 32, 256, 64]          320\n",
       "├─BatchNorm2d: 1-2                       [2, 32, 256, 64]          64\n",
       "├─ReLU: 1-3                              [2, 32, 256, 64]          --\n",
       "├─MaxPool2d: 1-4                         [2, 32, 128, 32]          --\n",
       "├─Conv2d: 1-5                            [2, 64, 128, 32]          18,496\n",
       "├─BatchNorm2d: 1-6                       [2, 64, 128, 32]          128\n",
       "├─ReLU: 1-7                              [2, 64, 128, 32]          --\n",
       "├─MaxPool2d: 1-8                         [2, 64, 64, 16]           --\n",
       "├─Dropout: 1-9                           [2, 64, 64, 16]           --\n",
       "├─Conv2d: 1-10                           [2, 128, 64, 16]          73,856\n",
       "├─BatchNorm2d: 1-11                      [2, 128, 64, 16]          256\n",
       "├─ReLU: 1-12                             [2, 128, 64, 16]          --\n",
       "├─MaxPool2d: 1-13                        [2, 128, 64, 8]           --\n",
       "├─Dropout: 1-14                          [2, 128, 64, 8]           --\n",
       "├─Linear: 1-15                           [2, 64, 64]               65,600\n",
       "├─LSTM: 1-16                             [2, 64, 1024]             8,667,136\n",
       "├─Linear: 1-17                           [2, 64, 30]               30,750\n",
       "==========================================================================================\n",
       "Total params: 8,856,606\n",
       "Trainable params: 8,856,606\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 30.50\n",
       "Params size (MB): 35.43\n",
       "Estimated Total Size (MB): 66.06\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_RNN()\n",
    "summary(model, input_size = (2, 1, 256, 64), device='cpu')  # inputsize = (batch_size, channels, image length, image width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T02:23:55.592189Z",
     "iopub.status.busy": "2021-08-09T02:23:55.591800Z",
     "iopub.status.idle": "2021-08-09T02:23:55.604239Z",
     "shell.execute_reply": "2021-08-09T02:23:55.603094Z",
     "shell.execute_reply.started": "2021-08-09T02:23:55.592149Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_pass(model, dataloader, optimizer, backwards=True, print_loss=True):\n",
    "    \n",
    "    if backwards == True:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct_char = 0\n",
    "    correct = 0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    for img, labels, label_length in dataloader:\n",
    "        \n",
    "        # Send to GPU\n",
    "        img = img.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label_length = label_length.to(device)\n",
    "        \n",
    "        \n",
    "        model.train()\n",
    "        y_pred = model(img.unsqueeze(1))\n",
    "        lsm = nn.LogSoftmax()\n",
    "        y_pred = lsm(y_pred)\n",
    "\n",
    "        yinput = y_pred.permute(1,0,2)  # input sequence length, batch_size, number of classes \n",
    "\n",
    "        N = labels.shape[0] # batch size \n",
    "        input_lengths = torch.ones(N,dtype=torch.long)*64\n",
    "\n",
    "        loss = lossFun(yinput, labels, input_lengths, label_length)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if backwards == True:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "  \n",
    "        # ACCURACY \n",
    "        \n",
    "        pred_nums = torch.argmax(y_pred, dim=2)\n",
    "        \n",
    "        # Character accuracy\n",
    "        for pred, label, length in zip(pred_nums, labels, label_length):\n",
    "            length = length.item()\n",
    "            pred = torch.split(pred, length, dim=0)\n",
    "            pred = pred[0]\n",
    "            label = torch.split(label, length, dim=0)\n",
    "            label = label[0]\n",
    "            correct_chars += torch.sum(pred==label) \n",
    "            total_chars += length\n",
    "\n",
    "                    \n",
    "        # Check if words are same\n",
    "        for i in range(N):\n",
    "            pr = pred_nums[i]\n",
    "            tr = labels[i]\n",
    "            if torch.equal(pr, tr.long()):\n",
    "                correct +=1\n",
    "                \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_correct_chars = correct_chars/total_chars\n",
    "    \n",
    "    return avg_loss, avg_correct_chars, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T05:13:59.115009Z",
     "iopub.status.busy": "2021-08-09T05:13:59.114668Z",
     "iopub.status.idle": "2021-08-09T09:15:41.605754Z",
     "shell.execute_reply": "2021-08-09T09:15:41.603681Z",
     "shell.execute_reply.started": "2021-08-09T05:13:59.114978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "CTC Loss: 24.0099\n",
      "Percent correct characters per word: 0.0716\n",
      "Number of correct words: 25\n",
      "Valid\n",
      "CTC Loss 22.8846\n",
      "Percent correct characters per word 0.0753\n",
      "Number of correct words 1\n",
      "\n",
      "Epoch:  1\n",
      "Train:\n",
      "CTC Loss: 22.3449\n",
      "Percent correct characters per word: 0.0838\n",
      "Number of correct words: 9\n",
      "Valid\n",
      "CTC Loss 21.5739\n",
      "Percent correct characters per word 0.0879\n",
      "Number of correct words 1\n",
      "\n",
      "Epoch:  2\n",
      "Train:\n",
      "CTC Loss: 21.5413\n",
      "Percent correct characters per word: 0.0863\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 21.3196\n",
      "Percent correct characters per word 0.0862\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  3\n",
      "Train:\n",
      "CTC Loss: 21.4167\n",
      "Percent correct characters per word: 0.087\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 21.3456\n",
      "Percent correct characters per word 0.0883\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  4\n",
      "Train:\n",
      "CTC Loss: 21.3512\n",
      "Percent correct characters per word: 0.0874\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 21.293\n",
      "Percent correct characters per word 0.0884\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  5\n",
      "Train:\n",
      "CTC Loss: 21.3182\n",
      "Percent correct characters per word: 0.0876\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 21.2421\n",
      "Percent correct characters per word 0.0896\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  6\n",
      "Train:\n",
      "CTC Loss: 21.2643\n",
      "Percent correct characters per word: 0.0875\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 21.1494\n",
      "Percent correct characters per word 0.0877\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  7\n",
      "Train:\n",
      "CTC Loss: 21.1932\n",
      "Percent correct characters per word: 0.0888\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 21.0171\n",
      "Percent correct characters per word 0.0899\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  8\n",
      "Train:\n",
      "CTC Loss: 21.3843\n",
      "Percent correct characters per word: 0.0871\n",
      "Number of correct words: 2\n",
      "Valid\n",
      "CTC Loss 22.0551\n",
      "Percent correct characters per word 0.0808\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  9\n",
      "Train:\n",
      "CTC Loss: 21.6365\n",
      "Percent correct characters per word: 0.0837\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 21.3352\n",
      "Percent correct characters per word 0.0881\n",
      "Number of correct words 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CNN_RNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "lossFun = nn.CTCLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(0)\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_correct_chars = []\n",
    "valid_correct_chars = []\n",
    "train_correct_words = []\n",
    "valid_correct_words = []\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch: ', epoch)\n",
    "    \n",
    "    train_avg_loss, train_avg_correct_chars, train_num_correct_words = one_pass(model, dl_train, optimizer)\n",
    "    train_losses.append(train_avg_loss)\n",
    "    train_correct_chars.append(train_avg_correct_chars)\n",
    "    train_correct_words.append(train_num_correct_words)\n",
    "    print(\"Train:\")\n",
    "    print(\"CTC Loss:\", round(train_avg_loss,4))\n",
    "    print(\"Percent correct characters per word:\", round(train_avg_correct_chars.item(),4))\n",
    "    print(\"Number of correct words:\", train_num_correct_words)\n",
    "\n",
    "    \n",
    "    valid_avg_loss, valid_avg_correct_chars, valid_num_correct_words = one_pass(model, dl_valid, optimizer, backwards=False)\n",
    "    valid_losses.append(valid_avg_loss)\n",
    "    valid_correct_chars.append(valid_avg_correct_chars)\n",
    "    valid_correct_words.append(valid_num_correct_words)\n",
    "    print(\"Valid\")\n",
    "    print(\"CTC Loss\", round(valid_avg_loss,4))\n",
    "    print(\"Percent correct characters per word\", round(valid_avg_correct_chars.item(),4))\n",
    "    print(\"Number of correct words\", valid_num_correct_words)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
