{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation of a Keras Architecture \n",
    "by Amee Tan & Evan Chen \n",
    "\n",
    "### Goal:\n",
    "The goal of this project was to take an existing Keras architecture and translate it into Pytorch. <br>\n",
    "The Keras notebook can be found here:https://www.kaggle.com/samfc10/handwriting-recognition-using-crnn-in-keras\n",
    "\n",
    "### Task: \n",
    "Given pictures of handwritten names, predict the name that was written in the picture. \n",
    "\n",
    "### Data: \n",
    "https://www.kaggle.com/landlord/handwriting-recognition <br>\n",
    "Train: 331,059 images <br>\n",
    "Valid: 41,382 images <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:28:42.697466Z",
     "iopub.status.busy": "2021-08-10T14:28:42.697121Z",
     "iopub.status.idle": "2021-08-10T14:28:51.552138Z",
     "shell.execute_reply": "2021-08-10T14:28:51.551175Z",
     "shell.execute_reply.started": "2021-08-10T14:28:42.697434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.5.3-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.5.3\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:28:53.597850Z",
     "iopub.status.busy": "2021-08-10T14:28:53.597525Z",
     "iopub.status.idle": "2021-08-10T14:28:54.944152Z",
     "shell.execute_reply": "2021-08-10T14:28:54.943303Z",
     "shell.execute_reply.started": "2021-08-10T14:28:53.597817Z"
    },
    "id": "hbeM9aEXGgh1"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "# Mixed Precision Training\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09hv06ZVGGzy"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:28:56.937377Z",
     "iopub.status.busy": "2021-08-10T14:28:56.936951Z",
     "iopub.status.idle": "2021-08-10T14:28:57.044377Z",
     "shell.execute_reply": "2021-08-10T14:28:57.043593Z",
     "shell.execute_reply.started": "2021-08-10T14:28:56.937339Z"
    },
    "id": "y6xlYTIjBQFe",
    "outputId": "a1c7a3bf-ad91-4722-e580-024208f9cef1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>IDENTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VALIDATION_0001.jpg</td>\n",
       "      <td>BILEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VALIDATION_0002.jpg</td>\n",
       "      <td>LAUMIONIER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VALIDATION_0003.jpg</td>\n",
       "      <td>LEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VALIDATION_0004.jpg</td>\n",
       "      <td>JEAN-ROCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VALIDATION_0005.jpg</td>\n",
       "      <td>RUPP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FILENAME    IDENTITY\n",
       "0  VALIDATION_0001.jpg       BILEL\n",
       "1  VALIDATION_0002.jpg  LAUMIONIER\n",
       "2  VALIDATION_0003.jpg         LEA\n",
       "3  VALIDATION_0004.jpg   JEAN-ROCH\n",
       "4  VALIDATION_0005.jpg        RUPP"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_validation_v2.csv') # Locally\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:28:57.475211Z",
     "iopub.status.busy": "2021-08-10T14:28:57.474844Z",
     "iopub.status.idle": "2021-08-10T14:28:57.881448Z",
     "shell.execute_reply": "2021-08-10T14:28:57.880668Z",
     "shell.execute_reply.started": "2021-08-10T14:28:57.475179Z"
    },
    "id": "3W03dwXmEZVo"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_train_v2.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_test_v2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:28:57.883292Z",
     "iopub.status.busy": "2021-08-10T14:28:57.882918Z",
     "iopub.status.idle": "2021-08-10T14:28:57.926412Z",
     "shell.execute_reply": "2021-08-10T14:28:57.925367Z",
     "shell.execute_reply.started": "2021-08-10T14:28:57.883257Z"
    },
    "id": "BS9uEjhhJZRV",
    "outputId": "0472dff6-650b-405e-9873-8deea2e3f17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls in train: 565\n",
      "Number of nulls in valid: 78\n"
     ]
    }
   ],
   "source": [
    "# Are there any null values? \n",
    "\n",
    "print(\"Number of nulls in train:\", df_train['IDENTITY'].isnull().sum())\n",
    "print(\"Number of nulls in valid:\",df_valid['IDENTITY'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:29:00.060144Z",
     "iopub.status.busy": "2021-08-10T14:29:00.059774Z",
     "iopub.status.idle": "2021-08-10T14:29:00.105071Z",
     "shell.execute_reply": "2021-08-10T14:29:00.104078Z",
     "shell.execute_reply.started": "2021-08-10T14:29:00.060097Z"
    },
    "id": "TXeVb9ICJqeQ",
    "outputId": "abc016dc-d18e-4599-e98d-f3b6337c8a3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>IDENTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>TRAIN_01914.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>TRAIN_02130.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>TRAIN_02625.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>TRAIN_04629.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>TRAIN_04873.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328491</th>\n",
       "      <td>TRAIN_328492.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328653</th>\n",
       "      <td>TRAIN_328654.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329959</th>\n",
       "      <td>TRAIN_329960.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330160</th>\n",
       "      <td>TRAIN_330161.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330164</th>\n",
       "      <td>TRAIN_330165.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                FILENAME IDENTITY\n",
       "1913     TRAIN_01914.jpg      NaN\n",
       "2129     TRAIN_02130.jpg      NaN\n",
       "2624     TRAIN_02625.jpg      NaN\n",
       "4628     TRAIN_04629.jpg      NaN\n",
       "4872     TRAIN_04873.jpg      NaN\n",
       "...                  ...      ...\n",
       "328491  TRAIN_328492.jpg      NaN\n",
       "328653  TRAIN_328654.jpg      NaN\n",
       "329959  TRAIN_329960.jpg      NaN\n",
       "330160  TRAIN_330161.jpg      NaN\n",
       "330164  TRAIN_330165.jpg      NaN\n",
       "\n",
       "[565 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at some of them \n",
    "df_train.loc[df_train['IDENTITY'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:29:00.298035Z",
     "iopub.status.busy": "2021-08-10T14:29:00.297705Z",
     "iopub.status.idle": "2021-08-10T14:29:00.413427Z",
     "shell.execute_reply": "2021-08-10T14:29:00.412581Z",
     "shell.execute_reply.started": "2021-08-10T14:29:00.298003Z"
    },
    "id": "9MWDoHyeKRJe"
   },
   "outputs": [],
   "source": [
    "# Drop the rows with null values for the label (IDENTITY column)\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_valid.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:29:00.478362Z",
     "iopub.status.busy": "2021-08-10T14:29:00.478100Z",
     "iopub.status.idle": "2021-08-10T14:29:00.536689Z",
     "shell.execute_reply": "2021-08-10T14:29:00.535726Z",
     "shell.execute_reply.started": "2021-08-10T14:29:00.478336Z"
    },
    "id": "XPeLYqcZCo6v",
    "outputId": "765bd88e-b850-4e8b-e734-d79ac6e31a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "12\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# How many unreadable images are there in each set? \n",
    "print(len(df_train.loc[df_train['IDENTITY']=='UNREADABLE']))\n",
    "print(len(df_valid.loc[df_valid['IDENTITY']=='UNREADABLE']))\n",
    "print(len(df_test.loc[df_test['IDENTITY']=='UNREADABLE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:29:02.041906Z",
     "iopub.status.busy": "2021-08-10T14:29:02.041560Z",
     "iopub.status.idle": "2021-08-10T14:29:02.118327Z",
     "shell.execute_reply": "2021-08-10T14:29:02.117485Z",
     "shell.execute_reply.started": "2021-08-10T14:29:02.041875Z"
    },
    "id": "v4VEmmGqDv0l"
   },
   "outputs": [],
   "source": [
    "# Remove the unreadable images from the train and valid sets\n",
    "\n",
    "df_train = df_train[df_train['IDENTITY'] != 'UNREADABLE']\n",
    "df_valid = df_valid[df_valid['IDENTITY'] != 'UNREADABLE']\n",
    "df_test = df_test[df_test['IDENTITY'] != 'UNREADABLE']\n",
    "\n",
    "df_train.reset_index(inplace = True, drop=True) \n",
    "df_valid.reset_index(inplace = True, drop=True)\n",
    "df_test.reset_index(inplace = True, drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:29:02.866690Z",
     "iopub.status.busy": "2021-08-10T14:29:02.866346Z",
     "iopub.status.idle": "2021-08-10T14:29:03.066888Z",
     "shell.execute_reply": "2021-08-10T14:29:03.066047Z",
     "shell.execute_reply.started": "2021-08-10T14:29:02.866655Z"
    },
    "id": "oY96cw9hFxjb"
   },
   "outputs": [],
   "source": [
    "# There are some labels that are lowercase. Convert all labels to uppercase\n",
    "\n",
    "df_train['IDENTITY'] = df_train['IDENTITY'].str.upper()\n",
    "df_valid['IDENTITY'] = df_valid['IDENTITY'].str.upper()\n",
    "df_test['IDENTITY'] = df_test['IDENTITY'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:29:04.143778Z",
     "iopub.status.busy": "2021-08-10T14:29:04.143451Z",
     "iopub.status.idle": "2021-08-10T14:29:04.399717Z",
     "shell.execute_reply": "2021-08-10T14:29:04.398721Z",
     "shell.execute_reply.started": "2021-08-10T14:29:04.143747Z"
    },
    "id": "yztN_FayJEyr",
    "outputId": "95ecf2ad-d35d-4153-cbd1-9d396797af67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        LABEL LENGTH\n",
      "count  330294.000000\n",
      "mean        6.546531\n",
      "std         2.123296\n",
      "min         1.000000\n",
      "25%         5.000000\n",
      "50%         6.000000\n",
      "75%         7.000000\n",
      "max        34.000000\n",
      "       LABEL LENGTH\n",
      "count  41280.000000\n",
      "mean       6.556613\n",
      "std        2.127069\n",
      "min        1.000000\n",
      "25%        5.000000\n",
      "50%        6.000000\n",
      "75%        7.000000\n",
      "max       21.000000\n",
      "       LABEL LENGTH\n",
      "count  41289.000000\n",
      "mean       6.545860\n",
      "std        2.137525\n",
      "min        1.000000\n",
      "25%        5.000000\n",
      "50%        6.000000\n",
      "75%        7.000000\n",
      "max       24.000000\n"
     ]
    }
   ],
   "source": [
    "# How long is the longest name that we'll encounter? \n",
    "\n",
    "df_train['LABEL LENGTH'] = df_train['IDENTITY'].apply(lambda x: len(x))\n",
    "df_valid['LABEL LENGTH'] = df_valid['IDENTITY'].apply(lambda x: len(x))\n",
    "df_test['LABEL LENGTH'] = df_test['IDENTITY'].apply(lambda x: len(x))\n",
    "\n",
    "print(df_train.describe()) # 34 for the training set \n",
    "print(df_valid.describe()) # 21 for the valid set\n",
    "print(df_test.describe()) # 24 for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VY8MexFGVl5"
   },
   "source": [
    "# Prepare Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:29:05.530985Z",
     "iopub.status.busy": "2021-08-10T14:29:05.530623Z",
     "iopub.status.idle": "2021-08-10T14:29:05.536807Z",
     "shell.execute_reply": "2021-08-10T14:29:05.535648Z",
     "shell.execute_reply.started": "2021-08-10T14:29:05.530946Z"
    },
    "id": "wmOClSZDF-Ca"
   },
   "outputs": [],
   "source": [
    "# Code borrowed from https://www.kaggle.com/samfc10/handwriting-recognition-using-crnn-in-keras\n",
    "\n",
    "def preprocess(img):\n",
    "    (h, w) = img.shape\n",
    "    \n",
    "    final_img = np.ones([64, 256])*255 # blank white image\n",
    "    \n",
    "    # Width and height are cropped if greater than 256x64; If smaler, image is padded with white pixesls\n",
    "    if w > 256:\n",
    "        img = img[:, :256]\n",
    "        \n",
    "    if h > 64:\n",
    "        img = img[:64, :]\n",
    "    \n",
    "    \n",
    "    final_img[:h, :w] = img\n",
    "    # Rotate clockwise\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUws6oFtPWBK"
   },
   "source": [
    "# Prepare Labels: Convert names into a sequence of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:29:06.945692Z",
     "iopub.status.busy": "2021-08-10T14:29:06.945364Z",
     "iopub.status.idle": "2021-08-10T14:29:06.951567Z",
     "shell.execute_reply": "2021-08-10T14:29:06.950406Z",
     "shell.execute_reply.started": "2021-08-10T14:29:06.945663Z"
    },
    "id": "zgK3fYYFOZQ7"
   },
   "outputs": [],
   "source": [
    "# Code adapted from same notebook as above \n",
    "\n",
    "alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\n",
    "max_str_len = 64 # max length of input labels\n",
    "num_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\n",
    "num_of_timestamps = 64 # max length of predicted labels \n",
    "\n",
    "def label_to_num(label):\n",
    "    label_num = []\n",
    "    for ch in label:\n",
    "        label_num.append(alphabets.find(ch))\n",
    "        \n",
    "    return np.array(label_num)\n",
    "\n",
    "def num_to_label(num):\n",
    "    ret = \"\"\n",
    "    for ch in num:\n",
    "        if ch == -1:  # CTC Blank\n",
    "            break\n",
    "        else:\n",
    "            ret+=alphabets[ch]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:29:07.157329Z",
     "iopub.status.busy": "2021-08-10T14:29:07.157064Z",
     "iopub.status.idle": "2021-08-10T14:29:07.161308Z",
     "shell.execute_reply": "2021-08-10T14:29:07.160528Z",
     "shell.execute_reply.started": "2021-08-10T14:29:07.157303Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_label(row):\n",
    "    label = np.zeros(max_str_len)\n",
    "    for i in range(max_str_len):\n",
    "        label[0:len(row)] = label_to_num(row)\n",
    "\n",
    "    return label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:29:08.278038Z",
     "iopub.status.busy": "2021-08-10T14:29:08.277696Z",
     "iopub.status.idle": "2021-08-10T14:31:41.467595Z",
     "shell.execute_reply": "2021-08-10T14:31:41.466820Z",
     "shell.execute_reply.started": "2021-08-10T14:29:08.278004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>IDENTITY</th>\n",
       "      <th>LABEL LENGTH</th>\n",
       "      <th>ENCODED LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00001.jpg</td>\n",
       "      <td>BALTHAZAR</td>\n",
       "      <td>9</td>\n",
       "      <td>[1.0, 0.0, 11.0, 19.0, 7.0, 0.0, 25.0, 0.0, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00002.jpg</td>\n",
       "      <td>SIMON</td>\n",
       "      <td>5</td>\n",
       "      <td>[18.0, 8.0, 12.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00003.jpg</td>\n",
       "      <td>BENES</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.0, 4.0, 13.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00004.jpg</td>\n",
       "      <td>LA LOVE</td>\n",
       "      <td>7</td>\n",
       "      <td>[11.0, 0.0, 28.0, 11.0, 14.0, 21.0, 4.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00005.jpg</td>\n",
       "      <td>DAPHNE</td>\n",
       "      <td>6</td>\n",
       "      <td>[3.0, 0.0, 15.0, 7.0, 13.0, 4.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330289</th>\n",
       "      <td>TRAIN_330957.jpg</td>\n",
       "      <td>LENNY</td>\n",
       "      <td>5</td>\n",
       "      <td>[11.0, 4.0, 13.0, 13.0, 24.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330290</th>\n",
       "      <td>TRAIN_330958.jpg</td>\n",
       "      <td>TIFFANY</td>\n",
       "      <td>7</td>\n",
       "      <td>[19.0, 8.0, 5.0, 5.0, 0.0, 13.0, 24.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330291</th>\n",
       "      <td>TRAIN_330959.jpg</td>\n",
       "      <td>COUTINHO DESA</td>\n",
       "      <td>13</td>\n",
       "      <td>[2.0, 14.0, 20.0, 19.0, 8.0, 13.0, 7.0, 14.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330292</th>\n",
       "      <td>TRAIN_330960.jpg</td>\n",
       "      <td>MOURAD</td>\n",
       "      <td>6</td>\n",
       "      <td>[12.0, 14.0, 20.0, 17.0, 0.0, 3.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330293</th>\n",
       "      <td>TRAIN_330961.jpg</td>\n",
       "      <td>HELOISE</td>\n",
       "      <td>7</td>\n",
       "      <td>[7.0, 4.0, 11.0, 14.0, 8.0, 18.0, 4.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330294 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                FILENAME       IDENTITY  LABEL LENGTH  \\\n",
       "0        TRAIN_00001.jpg      BALTHAZAR             9   \n",
       "1        TRAIN_00002.jpg          SIMON             5   \n",
       "2        TRAIN_00003.jpg          BENES             5   \n",
       "3        TRAIN_00004.jpg        LA LOVE             7   \n",
       "4        TRAIN_00005.jpg         DAPHNE             6   \n",
       "...                  ...            ...           ...   \n",
       "330289  TRAIN_330957.jpg          LENNY             5   \n",
       "330290  TRAIN_330958.jpg        TIFFANY             7   \n",
       "330291  TRAIN_330959.jpg  COUTINHO DESA            13   \n",
       "330292  TRAIN_330960.jpg         MOURAD             6   \n",
       "330293  TRAIN_330961.jpg        HELOISE             7   \n",
       "\n",
       "                                            ENCODED LABEL  \n",
       "0       [1.0, 0.0, 11.0, 19.0, 7.0, 0.0, 25.0, 0.0, 17...  \n",
       "1       [18.0, 8.0, 12.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0...  \n",
       "2       [1.0, 4.0, 13.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "3       [11.0, 0.0, 28.0, 11.0, 14.0, 21.0, 4.0, 0.0, ...  \n",
       "4       [3.0, 0.0, 15.0, 7.0, 13.0, 4.0, 0.0, 0.0, 0.0...  \n",
       "...                                                   ...  \n",
       "330289  [11.0, 4.0, 13.0, 13.0, 24.0, 0.0, 0.0, 0.0, 0...  \n",
       "330290  [19.0, 8.0, 5.0, 5.0, 0.0, 13.0, 24.0, 0.0, 0....  \n",
       "330291  [2.0, 14.0, 20.0, 19.0, 8.0, 13.0, 7.0, 14.0, ...  \n",
       "330292  [12.0, 14.0, 20.0, 17.0, 0.0, 3.0, 0.0, 0.0, 0...  \n",
       "330293  [7.0, 4.0, 11.0, 14.0, 8.0, 18.0, 4.0, 0.0, 0....  \n",
       "\n",
       "[330294 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ENCODED LABEL'] = df_train['IDENTITY'].apply(lambda x: encode_label(x))\n",
    "df_valid['ENCODED LABEL'] = df_valid['IDENTITY'].apply(lambda x: encode_label(x))\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:31:41.476506Z",
     "iopub.status.busy": "2021-08-10T14:31:41.476080Z",
     "iopub.status.idle": "2021-08-10T14:31:41.485496Z",
     "shell.execute_reply": "2021-08-10T14:31:41.484744Z",
     "shell.execute_reply.started": "2021-08-10T14:31:41.476444Z"
    },
    "id": "NVZ180TbIp3V"
   },
   "outputs": [],
   "source": [
    "# Create a dataset \n",
    "\n",
    "class HandwritingDataset(Dataset):\n",
    "    def __init__(self, df, folder_path):\n",
    "        self.df = df\n",
    "        self.folder_path = folder_path  # ex. '/content/train_v2/train/'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # retrieve image\n",
    "        path = self.folder_path+self.df.loc[idx,'FILENAME']\n",
    "        \n",
    "        # read the img\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img = preprocess(img)\n",
    "        \n",
    "        # convert to [0,1] scale -> normalize\n",
    "        img = torch.tensor(img / 255.).float()\n",
    "        \n",
    "        # Encode the label \n",
    "        label = torch.tensor(self.df.loc[idx,'ENCODED LABEL'])\n",
    "        #label = torch.tensor(label_to_num(self.df.loc[idx,'IDENTITY'])) # Returns label as a sequence of numbers \n",
    "        label_length = self.df.loc[idx,'LABEL LENGTH']\n",
    "        \n",
    "        return img, label, label_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:31:45.683588Z",
     "iopub.status.busy": "2021-08-10T14:31:45.683267Z",
     "iopub.status.idle": "2021-08-10T14:31:45.806769Z",
     "shell.execute_reply": "2021-08-10T14:31:45.805975Z",
     "shell.execute_reply.started": "2021-08-10T14:31:45.683559Z"
    },
    "id": "wjI7EL_NNXde",
    "outputId": "af2f0a51-7387-45af-a1cb-e80163614943"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 0.9686, 0.9961, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.9961, 0.9961]]),\n",
       " tensor([ 1.,  0., 11., 19.,  7.,  0., 25.,  0., 17.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=torch.float64),\n",
       " 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.iloc[:5000]\n",
    "ds_train = HandwritingDataset(df_train, '/kaggle/input/handwriting-recognition/train_v2/train/')\n",
    "next(iter(ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:31:46.362091Z",
     "iopub.status.busy": "2021-08-10T14:31:46.361736Z",
     "iopub.status.idle": "2021-08-10T14:31:46.383433Z",
     "shell.execute_reply": "2021-08-10T14:31:46.382672Z",
     "shell.execute_reply.started": "2021-08-10T14:31:46.362057Z"
    },
    "id": "uEiwKSHVJrM9",
    "outputId": "d93b3b3b-1d6f-4c90-8ed8-2fb47cace54b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
       " tensor([ 1.,  8., 11.,  4., 11.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=torch.float64),\n",
       " 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = df_valid.iloc[:500]\n",
    "ds_valid = HandwritingDataset(df_valid, '/kaggle/input/handwriting-recognition/validation_v2/validation/')\n",
    "\n",
    "next(iter(ds_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:31:47.739916Z",
     "iopub.status.busy": "2021-08-10T14:31:47.739584Z",
     "iopub.status.idle": "2021-08-10T14:31:47.744305Z",
     "shell.execute_reply": "2021-08-10T14:31:47.743442Z",
     "shell.execute_reply.started": "2021-08-10T14:31:47.739884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataloaders \n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size = 32, shuffle=True)\n",
    "dl_valid = DataLoader(ds_valid, batch_size = 32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T14:13:14.344881Z",
     "iopub.status.busy": "2021-08-09T14:13:14.344198Z",
     "iopub.status.idle": "2021-08-09T14:13:14.604732Z",
     "shell.execute_reply": "2021-08-09T14:13:14.603794Z",
     "shell.execute_reply.started": "2021-08-09T14:13:14.344834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9882, 0.9961],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9843, 0.9961, 0.9922],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.7333, 0.9882, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.0471, 0.2353, 0.3725],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.8471, 0.5020, 0.1216]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 1.0000, 0.9882],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.3843, 0.3608, 0.3961],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]),\n",
       " tensor([[ 1.,  8., 11.,  ...,  0.,  0.,  0.],\n",
       "         [11.,  0., 20.,  ...,  0.,  0.,  0.],\n",
       "         [11.,  4.,  0.,  ...,  0.,  0.,  0.],\n",
       "         ...,\n",
       "         [15., 17.,  8.,  ...,  0.,  0.,  0.],\n",
       "         [ 7., 20.,  6.,  ...,  0.,  0.,  0.],\n",
       "         [12.,  0., 14.,  ...,  0.,  0.,  0.]], dtype=torch.float64),\n",
       " tensor([ 5, 10,  3,  9,  4,  6,  6,  6, 11,  6,  4,  6,  7,  5,  7,  5,  7,  9,\n",
       "          8, 11,  6,  5,  8,  8,  8,  6,  5,  8, 11,  6,  4,  5])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pS7tEE3XK8r"
   },
   "source": [
    "## CNN Architecture --> RNN Arhitecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:58:27.884164Z",
     "iopub.status.busy": "2021-08-10T14:58:27.883682Z",
     "iopub.status.idle": "2021-08-10T14:58:27.905956Z",
     "shell.execute_reply": "2021-08-10T14:58:27.905050Z",
     "shell.execute_reply.started": "2021-08-10T14:58:27.884117Z"
    },
    "id": "rH4LIYXxD8Kn"
   },
   "outputs": [],
   "source": [
    "class CNN_RNN(nn.Module):\n",
    "    \"\"\"CNN and RNN model from class\"\"\"\n",
    "    def __init__(self, mish=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # same padding!\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "        # pooling\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=(1,2))\n",
    "        \n",
    "        # activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "\n",
    "        # batchnorm\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Linear Layer (Dense Layer)\n",
    "        self.linear1 = nn.Linear(in_features=1024, out_features=64)\n",
    "        \n",
    "        \n",
    "        self.linear2 = nn.Linear(in_features=1024, out_features=30)\n",
    "        \n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=64,hidden_size=512, \n",
    "                             batch_first=True, bidirectional=True, \n",
    "                             num_layers=2)\n",
    "        \n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # CNN\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool_1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool_1(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool_2(x)\n",
    "        \n",
    "\n",
    "        # CNN to RNN\n",
    "        # Reshape to a sequence vector that is 64 wide and 1024 deep \n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "\n",
    "        x = torch.reshape(x,(batch_size,64,-1)) # or 1024 instead of -1?? \n",
    "        \n",
    "        # Now we shrink the sequence vector to be 512 deep \n",
    "        x = self.linear1(x) \n",
    "\n",
    "\n",
    "        # RNN        \n",
    "        x = self.lstm1(x)[0] #[0] to get outputs, not hidden\n",
    "\n",
    "        # OUTPUT\n",
    "        x = self.linear2(x) # torch.Size([2, 2, 30])\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T14:13:14.628697Z",
     "iopub.status.busy": "2021-08-09T14:13:14.628117Z",
     "iopub.status.idle": "2021-08-09T14:13:15.160153Z",
     "shell.execute_reply": "2021-08-09T14:13:15.156937Z",
     "shell.execute_reply.started": "2021-08-09T14:13:14.628651Z"
    },
    "id": "elpMbwanO5TY",
    "outputId": "7b19b1ba-7b37-4beb-a171-90c76cbe3f13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_RNN                                  --                        --\n",
       "├─Conv2d: 1-1                            [2, 32, 256, 64]          320\n",
       "├─BatchNorm2d: 1-2                       [2, 32, 256, 64]          64\n",
       "├─ReLU: 1-3                              [2, 32, 256, 64]          --\n",
       "├─MaxPool2d: 1-4                         [2, 32, 128, 32]          --\n",
       "├─Conv2d: 1-5                            [2, 64, 128, 32]          18,496\n",
       "├─BatchNorm2d: 1-6                       [2, 64, 128, 32]          128\n",
       "├─ReLU: 1-7                              [2, 64, 128, 32]          --\n",
       "├─MaxPool2d: 1-8                         [2, 64, 64, 16]           --\n",
       "├─Dropout: 1-9                           [2, 64, 64, 16]           --\n",
       "├─Conv2d: 1-10                           [2, 128, 64, 16]          73,856\n",
       "├─BatchNorm2d: 1-11                      [2, 128, 64, 16]          256\n",
       "├─ReLU: 1-12                             [2, 128, 64, 16]          --\n",
       "├─MaxPool2d: 1-13                        [2, 128, 64, 8]           --\n",
       "├─Dropout: 1-14                          [2, 128, 64, 8]           --\n",
       "├─Linear: 1-15                           [2, 64, 64]               65,600\n",
       "├─LSTM: 1-16                             [2, 64, 1024]             8,667,136\n",
       "├─Linear: 1-17                           [2, 64, 30]               30,750\n",
       "==========================================================================================\n",
       "Total params: 8,856,606\n",
       "Trainable params: 8,856,606\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 30.50\n",
       "Params size (MB): 35.43\n",
       "Estimated Total Size (MB): 66.06\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_RNN()\n",
    "summary(model, input_size = (2, 1, 256, 64), device='cpu')  # inputsize = (batch_size, channels, image length, image width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T14:13:15.169910Z",
     "iopub.status.busy": "2021-08-09T14:13:15.167507Z",
     "iopub.status.idle": "2021-08-09T14:13:15.189665Z",
     "shell.execute_reply": "2021-08-09T14:13:15.188312Z",
     "shell.execute_reply.started": "2021-08-09T14:13:15.169864Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_pass(model, dataloader, optimizer, backwards=True, print_loss=True):\n",
    "    \n",
    "    \n",
    "    if backwards == True:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct_char = 0\n",
    "    correct = 0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    for img, labels, label_length in dataloader:\n",
    "        \n",
    "        # Send to GPU\n",
    "        img = img.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label_length = label_length.to(device)\n",
    "        \n",
    "        \n",
    "        model.train()\n",
    "        y_pred = model(img.unsqueeze(1))\n",
    "        lsm = nn.LogSoftmax()\n",
    "        y_pred = lsm(y_pred)\n",
    "\n",
    "        yinput = y_pred.permute(1,0,2)  # input sequence length, batch_size, number of classes \n",
    "\n",
    "        N = labels.shape[0] # batch size \n",
    "        input_lengths = torch.ones(N,dtype=torch.long)*64\n",
    "\n",
    "        loss = lossFun(yinput, labels, input_lengths, label_length)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if backwards == True:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "  \n",
    "        # ACCURACY \n",
    "        \n",
    "        pred_nums = torch.argmax(y_pred, dim=2)\n",
    "        \n",
    "        # Character accuracy\n",
    "        for pred, label, length in zip(pred_nums, labels, label_length):\n",
    "            length = length.item()\n",
    "            pred = torch.split(pred, length, dim=0)\n",
    "            pred = pred[0]\n",
    "            label = torch.split(label, length, dim=0)\n",
    "            label = label[0]\n",
    "            correct_chars += torch.sum(pred==label) \n",
    "            total_chars += length\n",
    "\n",
    "                    \n",
    "        # Check if words are same\n",
    "        for i in range(N):\n",
    "            pr = pred_nums[i]\n",
    "            tr = labels[i]\n",
    "            if torch.equal(pr, tr.long()):\n",
    "                correct +=1\n",
    "                \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_correct_chars = correct_chars/total_chars\n",
    "    \n",
    "    return avg_loss, avg_correct_chars, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with batch size and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T14:17:15.109695Z",
     "iopub.status.busy": "2021-08-09T14:17:15.109267Z",
     "iopub.status.idle": "2021-08-09T14:21:03.253911Z",
     "shell.execute_reply": "2021-08-09T14:21:03.252821Z",
     "shell.execute_reply.started": "2021-08-09T14:17:15.109663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "CTC Loss: 26.8664\n",
      "Percent correct characters per word: 0.0685\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 25.644\n",
      "Percent correct characters per word 0.0715\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  1\n",
      "Train:\n",
      "CTC Loss: 25.5211\n",
      "Percent correct characters per word: 0.0663\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 24.9334\n",
      "Percent correct characters per word 0.0664\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  2\n",
      "Train:\n",
      "CTC Loss: 25.1546\n",
      "Percent correct characters per word: 0.0667\n",
      "Number of correct words: 1\n",
      "Valid\n",
      "CTC Loss 24.7102\n",
      "Percent correct characters per word 0.0609\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  3\n",
      "Train:\n",
      "CTC Loss: 26.0625\n",
      "Percent correct characters per word: 0.0501\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 25.4158\n",
      "Percent correct characters per word 0.0514\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  4\n",
      "Train:\n",
      "CTC Loss: 25.3862\n",
      "Percent correct characters per word: 0.0665\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 24.7793\n",
      "Percent correct characters per word 0.0658\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  5\n",
      "Train:\n",
      "CTC Loss: 24.9546\n",
      "Percent correct characters per word: 0.072\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 24.8659\n",
      "Percent correct characters per word 0.0737\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  6\n",
      "Train:\n",
      "CTC Loss: 24.7924\n",
      "Percent correct characters per word: 0.07\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 25.0193\n",
      "Percent correct characters per word 0.0645\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  7\n",
      "Train:\n",
      "CTC Loss: 24.776\n",
      "Percent correct characters per word: 0.0737\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 24.3716\n",
      "Percent correct characters per word 0.0648\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  8\n",
      "Train:\n",
      "CTC Loss: 24.4448\n",
      "Percent correct characters per word: 0.0702\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 24.5811\n",
      "Percent correct characters per word 0.0682\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  9\n",
      "Train:\n",
      "CTC Loss: 24.5227\n",
      "Percent correct characters per word: 0.0691\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 24.9271\n",
      "Percent correct characters per word 0.0691\n",
      "Number of correct words 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline \n",
    "\n",
    "model = CNN_RNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "lossFun = nn.CTCLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(0)\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_correct_chars = []\n",
    "valid_correct_chars = []\n",
    "train_correct_words = []\n",
    "valid_correct_words = []\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch: ', epoch)\n",
    "    \n",
    "    train_avg_loss, train_avg_correct_chars, train_num_correct_words = one_pass(model, dl_train, optimizer)\n",
    "    train_losses.append(train_avg_loss)\n",
    "    train_correct_chars.append(train_avg_correct_chars)\n",
    "    train_correct_words.append(train_num_correct_words)\n",
    "    print(\"Train:\")\n",
    "    print(\"CTC Loss:\", round(train_avg_loss,4))\n",
    "    print(\"Percent correct characters per word:\", round(train_avg_correct_chars.item(),4))\n",
    "    print(\"Number of correct words:\", train_num_correct_words)\n",
    "\n",
    "    \n",
    "    valid_avg_loss, valid_avg_correct_chars, valid_num_correct_words = one_pass(model, dl_valid, optimizer, backwards=False)\n",
    "    valid_losses.append(valid_avg_loss)\n",
    "    valid_correct_chars.append(valid_avg_correct_chars)\n",
    "    valid_correct_words.append(valid_num_correct_words)\n",
    "    print(\"Valid\")\n",
    "    print(\"CTC Loss\", round(valid_avg_loss,4))\n",
    "    print(\"Percent correct characters per word\", round(valid_avg_correct_chars.item(),4))\n",
    "    print(\"Number of correct words\", valid_num_correct_words)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:55:35.227765Z",
     "iopub.status.busy": "2021-08-10T14:55:35.227411Z",
     "iopub.status.idle": "2021-08-10T14:55:35.238911Z",
     "shell.execute_reply": "2021-08-10T14:55:35.237811Z",
     "shell.execute_reply.started": "2021-08-10T14:55:35.227730Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epochs_gpu(batch_size, lr):\n",
    "    \n",
    "    dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "    dl_valid = DataLoader(ds_valid, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = CNN_RNN(mish=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr )\n",
    "#    lossFun = nn.CTCLoss()\n",
    "    \n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     device = torch.device(0)\n",
    "    model = model.to(device)\n",
    "\n",
    "    num_epochs = 10\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_correct_chars = []\n",
    "    valid_correct_chars = []\n",
    "    train_correct_words = []\n",
    "    valid_correct_words = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch: ', epoch)\n",
    "\n",
    "        train_avg_loss, train_avg_correct_chars, train_num_correct_words = one_pass(model, dl_train, optimizer)\n",
    "        train_losses.append(train_avg_loss)\n",
    "        train_correct_chars.append(train_avg_correct_chars)\n",
    "        train_correct_words.append(train_num_correct_words)\n",
    "        print(\"Train:\")\n",
    "        print(\"CTC Loss:\", round(train_avg_loss,4))\n",
    "        print(\"Percent correct characters per word:\", round(train_avg_correct_chars.item(),4))\n",
    "        print(\"Number of correct words:\", train_num_correct_words)\n",
    "\n",
    "\n",
    "        valid_avg_loss, valid_avg_correct_chars, valid_num_correct_words = one_pass(model, dl_valid, optimizer, backwards=False)\n",
    "        valid_losses.append(valid_avg_loss)\n",
    "        valid_correct_chars.append(valid_avg_correct_chars)\n",
    "        valid_correct_words.append(valid_num_correct_words)\n",
    "        print(\"Valid\")\n",
    "        print(\"CTC Loss\", round(valid_avg_loss,4))\n",
    "        print(\"Percent correct characters per word\", round(valid_avg_correct_chars.item(),4))\n",
    "        print(\"Number of correct words\", valid_num_correct_words)\n",
    "        print(\"\")\n",
    "        \n",
    "    return train_losses, valid_losses, valid_correct_chars, valid_correct_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T14:22:07.797987Z",
     "iopub.status.busy": "2021-08-09T14:22:07.797574Z",
     "iopub.status.idle": "2021-08-09T14:25:02.994625Z",
     "shell.execute_reply": "2021-08-09T14:25:02.993529Z",
     "shell.execute_reply.started": "2021-08-09T14:22:07.797954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "CTC Loss: 33.803\n",
      "Percent correct characters per word: 0.0746\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 32.3174\n",
      "Percent correct characters per word 0.0776\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  1\n",
      "Train:\n",
      "CTC Loss: 31.9879\n",
      "Percent correct characters per word: 0.0647\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 32.2615\n",
      "Percent correct characters per word 0.0676\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  2\n",
      "Train:\n",
      "CTC Loss: 31.7875\n",
      "Percent correct characters per word: 0.0682\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 32.06\n",
      "Percent correct characters per word 0.0645\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  3\n",
      "Train:\n",
      "CTC Loss: 31.2737\n",
      "Percent correct characters per word: 0.0734\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 32.7448\n",
      "Percent correct characters per word 0.0737\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  4\n",
      "Train:\n",
      "CTC Loss: 31.1584\n",
      "Percent correct characters per word: 0.073\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.7186\n",
      "Percent correct characters per word 0.0588\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  5\n",
      "Train:\n",
      "CTC Loss: 30.7832\n",
      "Percent correct characters per word: 0.0665\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.7288\n",
      "Percent correct characters per word 0.0712\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  6\n",
      "Train:\n",
      "CTC Loss: 30.655\n",
      "Percent correct characters per word: 0.0684\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.6762\n",
      "Percent correct characters per word 0.0661\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  7\n",
      "Train:\n",
      "CTC Loss: 30.5719\n",
      "Percent correct characters per word: 0.0721\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.4311\n",
      "Percent correct characters per word 0.0654\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  8\n",
      "Train:\n",
      "CTC Loss: 30.378\n",
      "Percent correct characters per word: 0.0734\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.574\n",
      "Percent correct characters per word 0.0651\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  9\n",
      "Train:\n",
      "CTC Loss: 30.3402\n",
      "Percent correct characters per word: 0.072\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.5298\n",
      "Percent correct characters per word 0.0636\n",
      "Number of correct words 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Increase batch size to 64\n",
    "train_losses1, valid_losses1, valid_correct_chars1, valid_correct_words1 = train_epochs_gpu(batch_size=64, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T14:25:32.864674Z",
     "iopub.status.busy": "2021-08-09T14:25:32.864253Z",
     "iopub.status.idle": "2021-08-09T14:28:17.421431Z",
     "shell.execute_reply": "2021-08-09T14:28:17.419887Z",
     "shell.execute_reply.started": "2021-08-09T14:25:32.864626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "CTC Loss: 40.921\n",
      "Percent correct characters per word: 0.0726\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 38.8885\n",
      "Percent correct characters per word 0.063\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  1\n",
      "Train:\n",
      "CTC Loss: 38.9995\n",
      "Percent correct characters per word: 0.0594\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 38.6706\n",
      "Percent correct characters per word 0.049\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  2\n",
      "Train:\n",
      "CTC Loss: 38.4457\n",
      "Percent correct characters per word: 0.0543\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 38.3796\n",
      "Percent correct characters per word 0.0536\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  3\n",
      "Train:\n",
      "CTC Loss: 38.6351\n",
      "Percent correct characters per word: 0.0491\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 39.0022\n",
      "Percent correct characters per word 0.0554\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  4\n",
      "Train:\n",
      "CTC Loss: 38.2428\n",
      "Percent correct characters per word: 0.0544\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 38.0206\n",
      "Percent correct characters per word 0.0645\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  5\n",
      "Train:\n",
      "CTC Loss: 38.0924\n",
      "Percent correct characters per word: 0.0591\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 38.293\n",
      "Percent correct characters per word 0.0658\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  6\n",
      "Train:\n",
      "CTC Loss: 38.6582\n",
      "Percent correct characters per word: 0.066\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 38.4306\n",
      "Percent correct characters per word 0.0685\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  7\n",
      "Train:\n",
      "CTC Loss: 37.977\n",
      "Percent correct characters per word: 0.0697\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 37.7302\n",
      "Percent correct characters per word 0.0648\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  8\n",
      "Train:\n",
      "CTC Loss: 37.5808\n",
      "Percent correct characters per word: 0.0629\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 37.3962\n",
      "Percent correct characters per word 0.0588\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  9\n",
      "Train:\n",
      "CTC Loss: 37.4178\n",
      "Percent correct characters per word: 0.0616\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 37.3579\n",
      "Percent correct characters per word 0.0615\n",
      "Number of correct words 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Increase learning rate \n",
    "train_losses1, valid_losses1, valid_correct_chars1, valid_correct_words1 = train_epochs_gpu(batch_size=128, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:48:47.852659Z",
     "iopub.status.busy": "2021-08-10T14:48:47.852321Z",
     "iopub.status.idle": "2021-08-10T14:48:47.864093Z",
     "shell.execute_reply": "2021-08-10T14:48:47.863274Z",
     "shell.execute_reply.started": "2021-08-10T14:48:47.852618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding lr scheduler \n",
    "\n",
    "def one_pass(model, dataloader, optimizer, backwards=True, print_loss=True):\n",
    "    \n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 100)   \n",
    "    lossFun = nn.CTCLoss()\n",
    "    \n",
    "    if backwards == True:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct_char = 0\n",
    "    correct = 0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "    for img, labels, label_length in dataloader:\n",
    "        \n",
    "        # Send to GPU\n",
    "        img = img.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label_length = label_length.to(device)\n",
    "        \n",
    "        \n",
    "        model.train()\n",
    "        y_pred = model(img.unsqueeze(1))\n",
    "        lsm = nn.LogSoftmax()\n",
    "        y_pred = lsm(y_pred)\n",
    "\n",
    "        yinput = y_pred.permute(1,0,2)  # input sequence length, batch_size, number of classes \n",
    "\n",
    "        N = labels.shape[0] # batch size \n",
    "        input_lengths = torch.ones(N,dtype=torch.long)*64\n",
    "\n",
    "        loss = lossFun(yinput, labels, input_lengths, label_length)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if backwards == True:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "  \n",
    "        # ACCURACY \n",
    "        \n",
    "        pred_nums = torch.argmax(y_pred, dim=2)\n",
    "        \n",
    "        # Character accuracy\n",
    "        for pred, label, length in zip(pred_nums, labels, label_length):\n",
    "            length = length.item()\n",
    "            pred = torch.split(pred, length, dim=0)\n",
    "            pred = pred[0]\n",
    "            label = torch.split(label, length, dim=0)\n",
    "            label = label[0]\n",
    "            correct_chars += torch.sum(pred==label) \n",
    "            total_chars += length\n",
    "\n",
    "                    \n",
    "        # Check if words are same\n",
    "        for i in range(N):\n",
    "            pr = pred_nums[i]\n",
    "            tr = labels[i]\n",
    "            if torch.equal(pr, tr.long()):\n",
    "                correct +=1\n",
    "                \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_correct_chars = correct_chars/total_chars\n",
    "    \n",
    "    return avg_loss, avg_correct_chars, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T14:46:32.105025Z",
     "iopub.status.busy": "2021-08-09T14:46:32.104518Z",
     "iopub.status.idle": "2021-08-09T14:49:29.197724Z",
     "shell.execute_reply": "2021-08-09T14:49:29.196631Z",
     "shell.execute_reply.started": "2021-08-09T14:46:32.104992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "CTC Loss: 33.624\n",
      "Percent correct characters per word: 0.0726\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.7609\n",
      "Percent correct characters per word 0.0801\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  1\n",
      "Train:\n",
      "CTC Loss: 31.7007\n",
      "Percent correct characters per word: 0.0727\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.8403\n",
      "Percent correct characters per word 0.067\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  2\n",
      "Train:\n",
      "CTC Loss: 31.202\n",
      "Percent correct characters per word: 0.0667\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.1687\n",
      "Percent correct characters per word 0.0682\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  3\n",
      "Train:\n",
      "CTC Loss: 31.0435\n",
      "Percent correct characters per word: 0.0702\n",
      "Number of correct words: 5\n",
      "Valid\n",
      "CTC Loss 30.5653\n",
      "Percent correct characters per word 0.0788\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  4\n",
      "Train:\n",
      "CTC Loss: 31.034\n",
      "Percent correct characters per word: 0.0673\n",
      "Number of correct words: 4\n",
      "Valid\n",
      "CTC Loss 30.8227\n",
      "Percent correct characters per word 0.0749\n",
      "Number of correct words 1\n",
      "\n",
      "Epoch:  5\n",
      "Train:\n",
      "CTC Loss: 30.6345\n",
      "Percent correct characters per word: 0.0717\n",
      "Number of correct words: 2\n",
      "Valid\n",
      "CTC Loss 30.7952\n",
      "Percent correct characters per word 0.0703\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  6\n",
      "Train:\n",
      "CTC Loss: 30.633\n",
      "Percent correct characters per word: 0.0737\n",
      "Number of correct words: 1\n",
      "Valid\n",
      "CTC Loss 30.5409\n",
      "Percent correct characters per word 0.0761\n",
      "Number of correct words 1\n",
      "\n",
      "Epoch:  7\n",
      "Train:\n",
      "CTC Loss: 30.6919\n",
      "Percent correct characters per word: 0.0707\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.392\n",
      "Percent correct characters per word 0.0725\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  8\n",
      "Train:\n",
      "CTC Loss: 30.377\n",
      "Percent correct characters per word: 0.0756\n",
      "Number of correct words: 1\n",
      "Valid\n",
      "CTC Loss 30.2251\n",
      "Percent correct characters per word 0.0746\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  9\n",
      "Train:\n",
      "CTC Loss: 30.2854\n",
      "Percent correct characters per word: 0.07\n",
      "Number of correct words: 1\n",
      "Valid\n",
      "CTC Loss 30.3909\n",
      "Percent correct characters per word 0.0743\n",
      "Number of correct words 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Increase batch size to 64 and incorporate learning rate \n",
    "train_losses1, valid_losses1, valid_correct_chars1, valid_correct_words1 = train_epochs_gpu(batch_size=64, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:32:28.572121Z",
     "iopub.status.busy": "2021-08-10T14:32:28.571729Z",
     "iopub.status.idle": "2021-08-10T14:32:28.587130Z",
     "shell.execute_reply": "2021-08-10T14:32:28.586179Z",
     "shell.execute_reply.started": "2021-08-10T14:32:28.572084Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN_RNN_no_dropout(nn.Module):\n",
    "    \"\"\"CNN and RNN model from class\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # same padding!\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # pooling\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=(1,2))\n",
    "        \n",
    "        # activation\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # dropout\n",
    "        #self.dropout = nn.Dropout(p)\n",
    "\n",
    "        # batchnorm\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Linear Layer (Dense Layer)\n",
    "        self.linear1 = nn.Linear(in_features=1024, out_features=64)\n",
    "        self.linear2 = nn.Linear(in_features=1024, out_features=30)\n",
    "\n",
    "        # RNN Layer --> Single LSTM with num_layers=2\n",
    "        #self.lstm1 = nn.LSTM(input_size=64, hidden_size=600, batch_first=True, bidirectional=True, num_layers=2, proj_size=512)\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=512, batch_first=True, bidirectional=True, num_layers=2)\n",
    "\n",
    "        self.unroll = nn.Flatten()\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # CNN\n",
    "        # Start with image that is 256 wide x 64 tall and 1 channel\n",
    "        # End with 64 wide x 8 tall and 128 channels\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool_1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool_1(x)\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool_2(x)\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "\n",
    "        # CNN to RNN\n",
    "        # Reshape to a sequence vector that is 64 wide and 1024 deep \n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "\n",
    "        x = torch.reshape(x,(batch_size,64,-1)) # or 1024 instead of -1?? \n",
    "\n",
    "        x = self.linear1(x) \n",
    "        \n",
    "        x = self.lstm1(x)[0] #[0] to get outputs, not hidden\n",
    "\n",
    "        # OUTPUT\n",
    "        x = self.linear2(x) # torch.Size([2, 2, 30])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:44:21.205232Z",
     "iopub.status.busy": "2021-08-10T14:44:21.204841Z",
     "iopub.status.idle": "2021-08-10T14:44:21.210888Z",
     "shell.execute_reply": "2021-08-10T14:44:21.209900Z",
     "shell.execute_reply.started": "2021-08-10T14:44:21.205202Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:44:21.742059Z",
     "iopub.status.busy": "2021-08-10T14:44:21.741727Z",
     "iopub.status.idle": "2021-08-10T14:44:21.754112Z",
     "shell.execute_reply": "2021-08-10T14:44:21.753266Z",
     "shell.execute_reply.started": "2021-08-10T14:44:21.742026Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epochs_gpu_no_dropout(batch_size, lr):\n",
    "    \n",
    "    dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "    dl_valid = DataLoader(ds_valid, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = CNN_RNN_no_dropout()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr )    \n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    num_epochs = 10\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_correct_chars = []\n",
    "    valid_correct_chars = []\n",
    "    train_correct_words = []\n",
    "    valid_correct_words = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch: ', epoch)\n",
    "\n",
    "        train_avg_loss, train_avg_correct_chars, train_num_correct_words = one_pass(model, dl_train, optimizer)\n",
    "        train_losses.append(train_avg_loss)\n",
    "        train_correct_chars.append(train_avg_correct_chars)\n",
    "        train_correct_words.append(train_num_correct_words)\n",
    "        print(\"Train:\")\n",
    "        print(\"CTC Loss:\", round(train_avg_loss,4))\n",
    "        print(\"Percent correct characters per word:\", round(train_avg_correct_chars.item(),4))\n",
    "        print(\"Number of correct words:\", train_num_correct_words)\n",
    "\n",
    "\n",
    "        valid_avg_loss, valid_avg_correct_chars, valid_num_correct_words = one_pass(model, dl_valid, optimizer, backwards=False)\n",
    "        valid_losses.append(valid_avg_loss)\n",
    "        valid_correct_chars.append(valid_avg_correct_chars)\n",
    "        valid_correct_words.append(valid_num_correct_words)\n",
    "        print(\"Valid\")\n",
    "        print(\"CTC Loss\", round(valid_avg_loss,4))\n",
    "        print(\"Percent correct characters per word\", round(valid_avg_correct_chars.item(),4))\n",
    "        print(\"Number of correct words\", valid_num_correct_words)\n",
    "        print(\"\")\n",
    "        \n",
    "    return train_losses, valid_losses, valid_correct_chars, valid_correct_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:48:51.454029Z",
     "iopub.status.busy": "2021-08-10T14:48:51.453694Z",
     "iopub.status.idle": "2021-08-10T14:51:41.511758Z",
     "shell.execute_reply": "2021-08-10T14:51:41.510136Z",
     "shell.execute_reply.started": "2021-08-10T14:48:51.453997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "CTC Loss: 33.3093\n",
      "Percent correct characters per word: 0.0855\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.8573\n",
      "Percent correct characters per word 0.0843\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  1\n",
      "Train:\n",
      "CTC Loss: 31.9543\n",
      "Percent correct characters per word: 0.0788\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.2054\n",
      "Percent correct characters per word 0.0767\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  2\n",
      "Train:\n",
      "CTC Loss: 31.7189\n",
      "Percent correct characters per word: 0.0725\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.1364\n",
      "Percent correct characters per word 0.0734\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  3\n",
      "Train:\n",
      "CTC Loss: 31.3784\n",
      "Percent correct characters per word: 0.0701\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.4014\n",
      "Percent correct characters per word 0.0813\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  4\n",
      "Train:\n",
      "CTC Loss: 31.2645\n",
      "Percent correct characters per word: 0.0681\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.9398\n",
      "Percent correct characters per word 0.0566\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  5\n",
      "Train:\n",
      "CTC Loss: 31.439\n",
      "Percent correct characters per word: 0.0694\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.2313\n",
      "Percent correct characters per word 0.0758\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  6\n",
      "Train:\n",
      "CTC Loss: 31.4386\n",
      "Percent correct characters per word: 0.0681\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.7705\n",
      "Percent correct characters per word 0.0715\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  7\n",
      "Train:\n",
      "CTC Loss: 30.8996\n",
      "Percent correct characters per word: 0.0662\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.5636\n",
      "Percent correct characters per word 0.0718\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  8\n",
      "Train:\n",
      "CTC Loss: 30.7931\n",
      "Percent correct characters per word: 0.0711\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.4686\n",
      "Percent correct characters per word 0.0712\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  9\n",
      "Train:\n",
      "CTC Loss: 30.6862\n",
      "Percent correct characters per word: 0.0675\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 30.8908\n",
      "Percent correct characters per word 0.0639\n",
      "Number of correct words 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lr scheduler + no dropout \n",
    "\n",
    "train_losses2, valid_losses2, valid_correct_chars2, valid_correct_words2 = train_epochs_gpu_no_dropout(batch_size=64, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T14:58:33.933387Z",
     "iopub.status.busy": "2021-08-10T14:58:33.932911Z",
     "iopub.status.idle": "2021-08-10T15:00:59.956965Z",
     "shell.execute_reply": "2021-08-10T15:00:59.956046Z",
     "shell.execute_reply.started": "2021-08-10T14:58:33.933346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "CTC Loss: 34.0709\n",
      "Percent correct characters per word: 0.0758\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 32.5416\n",
      "Percent correct characters per word 0.0706\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  1\n",
      "Train:\n",
      "CTC Loss: 32.5736\n",
      "Percent correct characters per word: 0.0701\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.773\n",
      "Percent correct characters per word 0.0667\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  2\n",
      "Train:\n",
      "CTC Loss: 31.7367\n",
      "Percent correct characters per word: 0.073\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.3094\n",
      "Percent correct characters per word 0.0667\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  3\n",
      "Train:\n",
      "CTC Loss: 31.7342\n",
      "Percent correct characters per word: 0.0605\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.9319\n",
      "Percent correct characters per word 0.0572\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  4\n",
      "Train:\n",
      "CTC Loss: 32.0528\n",
      "Percent correct characters per word: 0.0652\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.8245\n",
      "Percent correct characters per word 0.0551\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  5\n",
      "Train:\n",
      "CTC Loss: 31.6018\n",
      "Percent correct characters per word: 0.062\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.3268\n",
      "Percent correct characters per word 0.0691\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  6\n",
      "Train:\n",
      "CTC Loss: 31.0814\n",
      "Percent correct characters per word: 0.0612\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.2921\n",
      "Percent correct characters per word 0.0569\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  7\n",
      "Train:\n",
      "CTC Loss: 30.9551\n",
      "Percent correct characters per word: 0.0562\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.0947\n",
      "Percent correct characters per word 0.0591\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  8\n",
      "Train:\n",
      "CTC Loss: 30.8124\n",
      "Percent correct characters per word: 0.0569\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.4885\n",
      "Percent correct characters per word 0.0594\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  9\n",
      "Train:\n",
      "CTC Loss: 30.7986\n",
      "Percent correct characters per word: 0.0563\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 31.1952\n",
      "Percent correct characters per word 0.0569\n",
      "Number of correct words 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses3, valid_losses3, valid_correct_chars3, valid_correct_words3 = train_epochs_gpu(batch_size=64, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T15:01:03.534890Z",
     "iopub.status.busy": "2021-08-10T15:01:03.534545Z",
     "iopub.status.idle": "2021-08-10T15:03:50.632309Z",
     "shell.execute_reply": "2021-08-10T15:03:50.631400Z",
     "shell.execute_reply.started": "2021-08-10T15:01:03.534860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "CTC Loss: 25.889\n",
      "Percent correct characters per word: 0.0783\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 24.5113\n",
      "Percent correct characters per word 0.0743\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  1\n",
      "Train:\n",
      "CTC Loss: 25.3947\n",
      "Percent correct characters per word: 0.0783\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 26.5406\n",
      "Percent correct characters per word 0.0916\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  2\n",
      "Train:\n",
      "CTC Loss: 25.2977\n",
      "Percent correct characters per word: 0.0851\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 24.1977\n",
      "Percent correct characters per word 0.0728\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  3\n",
      "Train:\n",
      "CTC Loss: 24.8869\n",
      "Percent correct characters per word: 0.0765\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 23.9747\n",
      "Percent correct characters per word 0.0761\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  4\n",
      "Train:\n",
      "CTC Loss: 25.275\n",
      "Percent correct characters per word: 0.0756\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 24.5837\n",
      "Percent correct characters per word 0.0834\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  5\n",
      "Train:\n",
      "CTC Loss: 24.7644\n",
      "Percent correct characters per word: 0.0773\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 23.6574\n",
      "Percent correct characters per word 0.0721\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  6\n",
      "Train:\n",
      "CTC Loss: 24.2645\n",
      "Percent correct characters per word: 0.074\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 24.0209\n",
      "Percent correct characters per word 0.0807\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  7\n",
      "Train:\n",
      "CTC Loss: 24.7981\n",
      "Percent correct characters per word: 0.0726\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 23.9409\n",
      "Percent correct characters per word 0.0609\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  8\n",
      "Train:\n",
      "CTC Loss: 24.6115\n",
      "Percent correct characters per word: 0.074\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 23.3612\n",
      "Percent correct characters per word 0.0709\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  9\n",
      "Train:\n",
      "CTC Loss: 24.1975\n",
      "Percent correct characters per word: 0.0743\n",
      "Number of correct words: 0\n",
      "Valid\n",
      "CTC Loss 23.3797\n",
      "Percent correct characters per word 0.0761\n",
      "Number of correct words 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses3, valid_losses3, valid_correct_chars3, valid_correct_words3 = train_epochs_gpu(batch_size=32, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on full dataset\n",
    "- ReLU\n",
    "- batch size = 32\n",
    "- Cosine Annealing Learning Rate Scheduler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-11T04:04:29.527232Z",
     "iopub.status.busy": "2021-08-11T04:04:29.526439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "CTC Loss: 23.6313\n",
      "Percent correct characters per word: 0.0763\n",
      "Number of correct words: 15\n",
      "Valid\n",
      "CTC Loss 21.6213\n",
      "Percent correct characters per word 0.0948\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  1\n",
      "Train:\n",
      "CTC Loss: 20.2599\n",
      "Percent correct characters per word: 0.1137\n",
      "Number of correct words: 4\n",
      "Valid\n",
      "CTC Loss 18.4421\n",
      "Percent correct characters per word 0.1325\n",
      "Number of correct words 0\n",
      "\n",
      "Epoch:  2\n",
      "Train:\n",
      "CTC Loss: 17.8262\n",
      "Percent correct characters per word: 0.1421\n",
      "Number of correct words: 1\n",
      "Valid\n",
      "CTC Loss 16.6317\n",
      "Percent correct characters per word 0.1529\n",
      "Number of correct words 1\n",
      "\n",
      "Epoch:  3\n",
      "Train:\n",
      "CTC Loss: 16.9938\n",
      "Percent correct characters per word: 0.1516\n",
      "Number of correct words: 1\n",
      "Valid\n",
      "CTC Loss 19.8691\n",
      "Percent correct characters per word 0.097\n",
      "Number of correct words 1\n",
      "\n",
      "Epoch:  4\n",
      "Train:\n",
      "CTC Loss: 18.8868\n",
      "Percent correct characters per word: 0.106\n",
      "Number of correct words: 9\n",
      "Valid\n",
      "CTC Loss 18.2685\n",
      "Percent correct characters per word 0.1144\n",
      "Number of correct words 1\n",
      "\n",
      "Epoch:  5\n",
      "Train:\n",
      "CTC Loss: 17.6805\n",
      "Percent correct characters per word: 0.1267\n",
      "Number of correct words: 10\n",
      "Valid\n",
      "CTC Loss 16.8068\n",
      "Percent correct characters per word 0.1433\n",
      "Number of correct words 1\n",
      "\n",
      "Epoch:  6\n",
      "Train:\n",
      "CTC Loss: 15.8647\n",
      "Percent correct characters per word: 0.1583\n",
      "Number of correct words: 1\n",
      "Valid\n",
      "CTC Loss 15.9235\n",
      "Percent correct characters per word 0.1565\n",
      "Number of correct words 1\n",
      "\n",
      "Epoch:  7\n",
      "Train:\n",
      "CTC Loss: 14.8657\n",
      "Percent correct characters per word: 0.1747\n",
      "Number of correct words: 5\n",
      "Valid\n",
      "CTC Loss 14.2657\n",
      "Percent correct characters per word 0.1799\n",
      "Number of correct words 2\n",
      "\n",
      "Epoch:  8\n",
      "Train:\n",
      "CTC Loss: 14.0353\n",
      "Percent correct characters per word: 0.1825\n",
      "Number of correct words: 6\n",
      "Valid\n",
      "CTC Loss 13.6526\n",
      "Percent correct characters per word 0.1855\n",
      "Number of correct words 1\n",
      "\n",
      "Epoch:  9\n",
      "Train:\n",
      "CTC Loss: nan\n",
      "Percent correct characters per word: 0.1784\n",
      "Number of correct words: 8\n",
      "Valid\n",
      "CTC Loss nan\n",
      "Percent correct characters per word 0.1246\n",
      "Number of correct words 5\n",
      "\n",
      "Epoch:  10\n",
      "Train:\n",
      "CTC Loss: nan\n",
      "Percent correct characters per word: 0.1246\n",
      "Number of correct words: 31\n",
      "Valid\n",
      "CTC Loss nan\n",
      "Percent correct characters per word 0.1246\n",
      "Number of correct words 5\n",
      "\n",
      "Epoch:  11\n",
      "Train:\n",
      "CTC Loss: nan\n",
      "Percent correct characters per word: 0.1246\n",
      "Number of correct words: 31\n",
      "Valid\n",
      "CTC Loss nan\n",
      "Percent correct characters per word 0.1246\n",
      "Number of correct words 5\n",
      "\n",
      "Epoch:  12\n",
      "Train:\n",
      "CTC Loss: nan\n",
      "Percent correct characters per word: 0.1246\n",
      "Number of correct words: 31\n",
      "Valid\n",
      "CTC Loss nan\n",
      "Percent correct characters per word 0.1246\n",
      "Number of correct words 5\n",
      "\n",
      "Epoch:  13\n",
      "Train:\n",
      "CTC Loss: nan\n",
      "Percent correct characters per word: 0.1246\n",
      "Number of correct words: 31\n",
      "Valid\n",
      "CTC Loss nan\n",
      "Percent correct characters per word 0.1246\n",
      "Number of correct words 5\n",
      "\n",
      "Epoch:  14\n",
      "Train:\n",
      "CTC Loss: nan\n",
      "Percent correct characters per word: 0.1246\n",
      "Number of correct words: 31\n",
      "Valid\n",
      "CTC Loss nan\n",
      "Percent correct characters per word 0.1246\n",
      "Number of correct words 5\n",
      "\n",
      "Epoch:  15\n"
     ]
    }
   ],
   "source": [
    "# Train for real on 30 epochs \n",
    "\n",
    "ds_train = HandwritingDataset(df_train, '/kaggle/input/handwriting-recognition/train_v2/train/')\n",
    "ds_valid = HandwritingDataset(df_valid, '/kaggle/input/handwriting-recognition/validation_v2/validation/')\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size = 64, shuffle=True)\n",
    "dl_valid = DataLoader(ds_valid, batch_size = 64, shuffle=False)\n",
    "\n",
    "train_losses, valid_losses, valid_correct_chars, valid_correct_words = train_epochs_gpu(batch_size=32, lr=0.001, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "Kaggle GPU timed out after epoch 14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
